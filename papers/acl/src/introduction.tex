% vim: set tw=78 sts=2 sw=2 ts=8 aw et ai:

Traditionally, historic events have been analyzed from the perspective of carefully selected texts, deemed historically significant. This has allowed historians to paint accurate descriptions of important events in our history, from a variety of perspectives: the underlying motives and actions that lead to a particular event, the narrative of the event (as a sequence of minor events) and the influence that said event has had on humans and their culture. In recent times, the sources for historians have diversified due to advancements in technology, but written texts still remain invaluable for this task.

However, as proven by the recent advent of the field of culturomics, introduced in \newcite{Michel14012011}, there is much to be learned by analyzing the large collections of books available in electronic form. More specifically, by seeking patterns in the time series of the frequency of a given word as a function of the year, it is possible to make clever observations in fields such as linguistics (grammar evolution), but also in areas pertaining to social sciences, such as collective memory, adoption of technology and censorship.

This paper delves deeper into the implications of this approach to the analysis of historic events. Thus, the purpose is to devise a model that can be used for the identification of important events in texts, by using quantitative data collected from millions of books instead of relying on understanding a few select texts.
