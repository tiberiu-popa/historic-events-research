% vim: set tw=78 sts=2 sw=2 ts=8 aw et ai:

\subsection{Corpus and Historical Relevance}

Our analysis is based on the Google Books Ngram Corpus. Let us denote the normalized time series for a given word by $w_i$ by $\left\{ s_{i, t} \right\}_{t = 1500}^{2008}$, which is smoothed using a central moving 5-average.

Instead of using the raw data, the historical relevance of an n-gram for a given year is modeled on a discrete scale: integers in $\left[ 0, 10 \right]$, where $0$ reflects the n-gram's lack of importance and $10$ reflects a year-defining n-gram. This notion is used for detecting bursty features, as defined in \newcite{Fung05parameterfree}, where the goal was detecting events on smaller corpora such as the 1-year Reuters News Corpus.

\subsection{Historical Relevance Algorithms}
\label{sec:historical-relevance-algorithms}
\input{src/model/historical-relevance-algorithms}

\subsection{Historically Relevant Documents and Topic Models}

For each year $t \in \left[ 1500, 2008 \right]$, we build its historically relevant document $d_t$ as follows: we include each $w_i$ (that satisfies $r_{i, t} > 0$) exactly $r_{i, t}$ times. Topic models seem most suitable for automatically analyzing the data, as they are designed for discovering the hidden thematic structure in document collections \newcite{Blei:2012:PTM:2133806.2133826}. The specific algorithm used in this paper is Latent Dirichlet Allocation (LDA) \newcite{Blei:2003:LDA:944919.944937}, but other topic detection methods shall be investigated in the future. Upon applying it to the historically relevant documents, the topics found by the algorithm should represent similar types of historic events, while the topic distribution for any given year should represent the underlying historic events. However, we have found that most times recurrent themes for consecutive years are grouped into a topic.
