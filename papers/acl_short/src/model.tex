% vim: set tw=78 sts=2 sw=2 ts=8 aw et ai:

\subsection{Corpus and Historical Relevance}

The analysis shall be based on the Google Books Ngram Corpus. Let us denote the normalized time series for a given word $w_i$ by $\left\{ s_{i, t} \right\}_{t = 1500}^{2008}$, smoothed using the central moving 5-average.

Instead of using the raw data, the historical relevance of an n-gram in a given year is modeled on a discrete scale, for example the integers in $\left[ 0, 10 \right]$, where $0$ would reflect the n-gram's lack of importance and $10$ would reflect a year-defining n-gram. This notion is used for detecting bursty features, as defined in \newcite{Fung05parameterfree}, where the goal was detecting events on smaller corpora such as the 1-year Reuters News Corpus.

\subsection{Historical Relevance Algorithms}
\label{sec:historical-relevance-algorithms}
\input{src/model/historical-relevance-algorithms}

\subsection{Historically Relevant Documents and Topic Models}

For each year $t \in \left[ 1500, 2008 \right]$, we build its historically relevant document $d_t$ as follows: we include each $w_i$ (that satisfies $r_{i, t} > 0$) exactly $r_{i, t}$ times. Topic models seem most suitable for automatically analyzing the data, as they are designed for discovering the hidden thematic structure in document collections \newcite{Blei:2012:PTM:2133806.2133826}. The specific algorithm used in this paper is the Latent Dirichlet Allocation (LDA) \newcite{Blei:2003:LDA:944919.944937}. Upon applying it to the historically relevant documents, ideally the topics found by the algorithm should represent the types of historic events, while the topic distribution for any given year should represent the underlying historic events. However, what ends up happening is that recurrent themes for consecutive years are grouped into a topic.
